{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f37ab23-475a-4f41-9bfb-58a36d581afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9410cb-33fc-4e0f-9d4b-bb7d4e28cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will only keep the duplicate with the longest sequence\n",
    "def fastaDeDupeDF(df):\n",
    "    \n",
    "    #making a new column for strain, extracted from the strain field (1st field) in the header\n",
    "    df['strain'] = df['header'].str.split(\"|\").str[0]\n",
    "\n",
    "    # df.duplicated returns boolean Series denoting duplicate rows in the strain column, if you would like to see which ones they are\n",
    "    # duplicated_strains = df[df.duplicated(subset=\"strain\")][['strain','sequence']]\n",
    "    # print(duplicated_strains.strain.unique())\n",
    "    \n",
    "    #sorts in ascending order all the sequences by length, then makes unique\n",
    "    #groups of strains, taking the last row that has the longest sequence\n",
    "    df = df.iloc[df[\"sequence\"].str.len().sort_values().index].groupby(\"strain\").tail(1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed5ebc-6147-4a9c-8953-e4046691e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genbankPrep(fasta_file,fasta_output):\n",
    "\n",
    "    # metadata file given by genbank needs some initial cleaning up; name = strain\n",
    "    # metadata= pd.read_csv(metadata_file)\n",
    "    # metadata['name'] = metadata['name'].str.replace(' ', '_')\n",
    "    # metadata['name'] = '>' + metadata['name'].astype(str)\n",
    "\n",
    "    #convert the fasta file into a df, where the header and sequence are two separate columns\n",
    "    fasta_data = []\n",
    "    with open(fasta_file, \"r\") as f:\n",
    "        header = \"\"\n",
    "        sequence = \"\"\n",
    "        for line in f:\n",
    "            if line.startswith(\">\"):\n",
    "                if header != \"\":\n",
    "                    fasta_data.append({\"header\": header, \"sequence\": sequence})\n",
    "                header = line.strip()\n",
    "                sequence = \"\"\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "        fasta_data.append({\"header\": header, \"sequence\": sequence})\n",
    "\n",
    "    df = pd.DataFrame(fasta_data)\n",
    "\n",
    "    #making a new column for each field\n",
    "    #this allows you to be flexible with the header\n",
    "\n",
    "    df['header'] = df['header'].str.replace(' ', '_')\n",
    "    df['Strain'] = df['header'].str.split(\"|\").str[0]\n",
    "    df['Accession'] = df['header'].str.split(\"|\").str[1]\n",
    "    df['Subtype'] = df['header'].str.split(\"|\").str[2]\n",
    "    df['Date'] = df['header'].str.split(\"|\").str[3]\n",
    "    df['Host'] = df['header'].str.split(\"|\").str[4]\n",
    "    df['Country'] = df['header'].str.split(\"|\").str[5]\n",
    "\n",
    "    df.Country.replace('Viet_Nam', 'Vietnam' , inplace =True)    \n",
    "    df = df[df[\"Country\"] != \"\"]\n",
    "    df = df[~df[\"Strain\"].str.contains(\"Equine_influenza_virus_H3N8\")]\n",
    "    df = df[~df[\"Subtype\"].str.contains(\"H3Nx|H3,mixed|mixed,H3|mixed,_H3|Mixed,H3|mixed.H3\")]\n",
    "    df.Subtype.replace('H3N6,H3', 'H3N6', inplace =True)\n",
    "\n",
    "    df['Species'] = df['Strain'].str.split(\"/\").str[1]\n",
    "\n",
    "    #adding region data\n",
    "    regions = pd.read_csv('regions.csv')\n",
    "    df = df.merge(regions,left_on = df[\"Country\"].str.lower(), right_on= regions[\"country\"], how= \"left\")\n",
    "    \n",
    "    df['header'] = df[['Strain', 'Accession', 'Subtype', 'Date', 'Host', 'country', 'Species', 'region']].apply('|'.join, axis=1)\n",
    "    #this drops all duplicates, keeping the longest sequence, will throw errors if there are no duplicates present\n",
    "    fastaDeDupeDF(df)\n",
    "\n",
    "    with open(fasta_output, \"w\") as f:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(f\"{row['header']}\\n\")\n",
    "            f.write(f\"{row['sequence']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02670099-b34f-4207-89ee-d68130376fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gisaidPrep(fasta_file,fasta_output):\n",
    "    metadata = pd.read_csv('H3Nx-GISAID-all-metadata.tsv', sep='\\t')\n",
    "\n",
    "    #replacing any spaces in the Isolate_Name column with underscores and adding the > character so that you can find matches in the fa file\n",
    "    metadata['Isolate_Name'] = metadata['Isolate_Name'].str.replace(' ', '_')\n",
    "    metadata['Isolate_Name'] = '>' + metadata['Isolate_Name'].astype(str)\n",
    "\n",
    "    #extracting the country name as the second value in the location column (location is formatted continent/country/state/county)\n",
    "    #drops any sequences where location or country data is not available\n",
    "    metadata.dropna(subset=['Location'], inplace=True)\n",
    "    metadata['Country'] = metadata['Location'].str.split('/').str[1].str.strip()\n",
    "    metadata.dropna(subset=['Country'], inplace=True)\n",
    "\n",
    "    #convert the fasta file into a df, where the header and sequence are two separate columns\n",
    "    fasta_data = []\n",
    "    with open(fasta_file, \"r\") as f:\n",
    "        header = \"\"\n",
    "        sequence = \"\"\n",
    "        for line in f:\n",
    "            if line.startswith(\">\"):\n",
    "                if header != \"\":\n",
    "                    fasta_data.append({\"header\": header, \"sequence\": sequence})\n",
    "                header = line.strip()\n",
    "                sequence = \"\"\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "        fasta_data.append({\"header\": header, \"sequence\": sequence})\n",
    "\n",
    "    df = pd.DataFrame(fasta_data)\n",
    "\n",
    "    #making a new column for each field. this allows you to be flexible with the header\n",
    "    df['Strain'] = df['header'].str.split(\"|\").str[0]\n",
    "    df['Accession'] = df['header'].str.split(\"|\").str[1]\n",
    "    df['Segment'] = df['header'].str.split(\"|\").str[2]\n",
    "    df['Date'] = df['header'].str.split(\"|\").str[3]\n",
    "\n",
    "    #dropping the duplicates, keeping the longest sequence, will throw errors if there are no duplicates present\n",
    "    fastaDeDupeDF(df)\n",
    "\n",
    "    #merging metadata with df on Isolate_Name column, adding metadata columns youre interested in\n",
    "    merged = pd.merge(df, metadata[['Isolate_Name', 'Subtype', 'Country', 'Host']], left_on='Strain', right_on='Isolate_Name')\n",
    "\n",
    "    merged.Segment = merged.Subtype\n",
    "    merged.Accession = \"EPI\" + merged.Accession\n",
    "\n",
    "    #country + host QC and replacing spaces\n",
    "    merged.Country.replace('United States', 'USA', inplace =True)\n",
    "    merged.Country.replace('Korea, Republic of', 'South Korea' , inplace =True)\n",
    "    merged.Country.replace('Russian Federation', 'Russia' , inplace =True)\n",
    "    merged.Country.replace('Hong Kong (SAR)', 'Hong Kong', inplace =True)\n",
    "    merged.Country.replace(\"Lao, People's Democratic Republic\", \"Laos\", inplace =True)\n",
    "    merged.Country = merged.Country.str.replace(' ', '_')\n",
    "    merged.Host = merged.Host.str.replace(' ', '_')\n",
    "    \n",
    "    #adding region data\n",
    "    regions = pd.read_csv('regions.csv')\n",
    "    merged = merged.merge(regions,left_on = merged[\"Country\"].str.lower(), right_on= regions[\"country\"], how= \"left\")\n",
    "\n",
    "    #Adding host data to match genbank host field\n",
    "    \n",
    "    avian_list = ['Duck', 'Swan', 'Goose', 'Other_avian', 'Chicken', 'Anas_platyrhynchos', \n",
    "                'Anas_acuta', 'Turkey', 'Anas_discors', 'Anas_carolinensis', \n",
    "                'Anas_clypeata', 'Anas_sp.', 'Arenaria_interpres', 'Anas_americana',\n",
    "                'Anas_rubripes', 'Anas_strepera', 'Anas_querquedula', 'Larus_atricilla',\n",
    "                'Guineafowl', 'Anas_crecca', 'Larus_hyperboreus', 'Gallus_gallus', \n",
    "                'Calidris_canutus', 'Melanitta_nigra', 'Tadorna_feruginea', 'Tadorna_tadorna',\n",
    "                'Anser_caerulescens', 'Aythya_collaris', 'Anser_albifrons', 'Somateria_fischeri',\n",
    "                'Calidris_alpina', 'Anas_georgica', 'Chen_canagica', 'Larus_glaucescens',\n",
    "                'Anas_cyanoptera', 'Calidris_alba', 'Chroicocephalus_ridibundus',\n",
    "                'Leucophaeus_atricilla', 'Calidris_pusilla', 'Sandpiper', 'American_wigeon', \n",
    "                'Mallard', 'Baikal_teal', 'Eurasian_curlew', 'Blue-winged_teal', \n",
    "                'Anseriformes_sp.', 'Anas_platyrhynchos_var._domesticus', \n",
    "                'Anas_platyrhynchos_x_Anas_acuta', 'Emperor_goose', 'American_black_duck', \n",
    "                'Pink-eared_duck', 'Anser_cygnoides', 'Ruddy_turnstone', 'Common_teal',\n",
    "                'Northern_pintail', 'Cinnamon_Teal', 'Mallard_duck', 'Wild_waterfowl',\n",
    "                'Grey_teal', 'Bucephala_albeola', 'Wild_bird', 'Gull', 'Northern_shoveler', \n",
    "                'Corvus_frugilegus', 'Branta_leucopsis', 'Oxyura_jamaicensis', 'Aix_sponsa', 'Cygnus_cygnus', \n",
    "                'Coturnix', 'Larus_argentatus', 'Cairina_moschata', 'Pheasant', 'Greylag_goose',\n",
    "                'Wild_birds', 'Green-winged_teal', 'Teal', 'Anser_fabalis', 'Cygnus_columbianus', \n",
    "                'Clangula_hyemalis', 'Netta_rufina']\n",
    "\n",
    "    swine_list = ['Sus_scrofa_scrofa', 'Sus_scrofa', 'Sus_scrofa_domesticus', 'Pig']\n",
    "    feline_list = ['Felis_catus']\n",
    "    canine_list = ['Canis_lupus_familiaris']\n",
    "    equine_list = ['Equus_caballus', 'Horse']\n",
    "\n",
    "    merged.loc[merged['Host'].isin(avian_list), 'Host_Type'] = 'Avian'\n",
    "    merged.loc[merged['Host'].isin(swine_list), 'Host_Type'] = 'Swine'\n",
    "    merged.loc[merged['Host'].isin(equine_list), 'Host_Type'] = 'Equine'\n",
    "    merged.loc[merged['Host'].isin(feline_list), 'Host_Type'] = 'Feline'\n",
    "    merged.loc[merged['Host'].isin(canine_list), 'Host_Type'] = 'Canine'\n",
    "    merged.loc[~merged['Host'].isin(avian_list + swine_list + equine_list + feline_list + canine_list), 'Host_Type'] = merged['Host']\n",
    "    print(merged.Host_Type.unique())\n",
    "\n",
    "    merged['header'] = merged[['Strain', 'Accession', 'Segment', 'Date', 'Host_Type', 'country', 'Host', 'region']].apply('|'.join, axis=1)\n",
    "\n",
    "    #writing new fasta file where the header and sequence columns are turned back into rows  \n",
    "    with open(fasta_output, \"w\") as f:\n",
    "        for index, row in merged.iterrows():\n",
    "            f.write(f\"{row['header']}\\n\")\n",
    "            f.write(f\"{row['sequence']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e5c2e-fd19-4903-920d-4040fb7e2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speciesClean(fasta_input,fasta_output):\n",
    "\n",
    "    #convert the fasta file into a df, where the header and sequence are two separate columns\n",
    "    #this assumes that you have a Species field (here it is coded as field 7) \n",
    "    #in the header that needs cleaning up. the header must have no spaces, only underscores\n",
    "    fasta_data = []\n",
    "    with open(fasta_input + \".fa\", \"r\") as f:\n",
    "        header = \"\"\n",
    "        sequence = \"\"\n",
    "        for line in f:\n",
    "            if line.startswith(\">\"):\n",
    "                if header != \"\":\n",
    "                    fasta_data.append({\"header\": header, \"sequence\": sequence})\n",
    "                header = line.strip()\n",
    "                sequence = \"\"\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "        fasta_data.append({\"header\": header, \"sequence\": sequence})\n",
    "\n",
    "    df = pd.DataFrame(fasta_data)\n",
    "\n",
    "    df['Strain'] = df['header'].str.split(\"|\").str[0]\n",
    "    df['Accession'] = df['header'].str.split(\"|\").str[1]\n",
    "    df['Subtype'] = df['header'].str.split(\"|\").str[2]\n",
    "    df['Date'] = df['header'].str.split(\"|\").str[3]\n",
    "    df['Host'] = df['header'].str.split(\"|\").str[4]\n",
    "    df['Country'] = df['header'].str.split(\"|\").str[5]\n",
    "    df['Species'] = df['header'].str.lower().str.split(\"|\").str[6]\n",
    "    df['Region'] = df['header'].str.lower().str.split(\"|\").str[7]\n",
    "    \n",
    "    #print(df.Species.unique())\n",
    "    \n",
    "    species = pd.read_csv('species.csv')\n",
    "\n",
    "    #some cleanup\n",
    "    df = df[~df[\"Species\"].str.contains(\"animal\")]\n",
    "    df = df[~df[\"Subtype\"].str.contains(\"H3Nx|H3,mixed|mixed,H3|mixed,_H3|Mixed,H3|mixed.H3\")]\n",
    "    df.Subtype.replace('H3N6,H3', 'H3N6', inplace =True)\n",
    "    \n",
    "    #theres probably a better way to do this\n",
    "\n",
    "    df = df.merge(species,left_on = df[\"Species\"].str.lower(), right_on= species[\"annotated\"].str.lower(), how= \"left\")\n",
    "    df['correction']=df['correction'].str.lower()\n",
    "    df.loc[df['correction'].notnull(), 'Species'] = df['correction']\n",
    "    df.drop(['correction', 'broad', 'annotated', 'order', 'key_0'], axis=1, inplace =True)\n",
    "    df = df.merge(species,left_on = df[\"Species\"].str.lower(), right_on= species[\"correction\"].str.lower(), how= \"left\")\n",
    "    \n",
    "    df['Correction']=df['correction'].str.lower()\n",
    "    df[\"Broad\"] = df['broad']\n",
    "    df[\"Order\"] = df['order']\n",
    "    df.drop(['key_0'], axis=1, inplace =True)\n",
    "\n",
    "    #if you get an error that there are floats instead of strings, add these species to the species.csv\n",
    "    print(df.Species.loc[df['correction'].isnull()].unique())\n",
    "\n",
    "    #merging will create duplicates\n",
    "    df.drop_duplicates(subset=['Strain'], keep='first', inplace=True, ignore_index=True)\n",
    "    \n",
    "    df['header'] = df[['Strain', 'Accession', 'Subtype', 'Date', 'Host', 'Country', 'Region', 'Correction', 'Broad','Order']].apply('|'.join, axis=1)\n",
    "\n",
    "    with open(fasta_output, \"w\") as f:\n",
    "         for index, row in df.iterrows():\n",
    "             f.write(f\"{row['header']}\\n\")\n",
    "             f.write(f\"{row['sequence']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
